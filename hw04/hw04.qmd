---
title: "Problem Set 4"
format: 
  html:
    embed-resources: true
    toc: true
    toc-location: right
    toc-title: "Content"
editor: visual
---

## About this file

This is the Yicun Duan's (umich id: 62178151) report of STAT 506's Problem Set 4. Here is the link to my [GitHub repository](https://github.com/YicunDuanUMich/r_hw04).

## Problem 1 - Tidyverse

### a

We first load the dataset and tidyverse library.

```{r}
#| code-fold: show
#| code-summary: "The code for Problem 1-a"
#| warning: true
#| error: true

rm(list = ls())

library(nycflights13)
library(tidyverse)

```

We make two tables to show the mean and median departure/arrival delay per airport.

```{r}
#| code-fold: show
#| code-summary: "The code for Problem 1-a"
#| warning: true
#| error: true

dep_airport_tab <- flights %>% 
        select(flight, origin, dep_delay) %>%
        left_join(airports, by = join_by(origin == faa)) %>%
        select(flight, name, dep_delay) %>%
        rename(dep_airport_name = name) %>%
        group_by(dep_airport_name) %>%
        summarize(mean_dep_delay = mean(dep_delay, na.rm = TRUE),
                  median_dep_delay = median(dep_delay, na.rm = TRUE)) %>%
        ungroup() %>%
        arrange(desc(mean_dep_delay))
print(dep_airport_tab, n = Inf)

arr_airport_tab <- flights %>% 
        select(flight, dest, arr_delay) %>%
        left_join(airports, by = join_by(dest == faa)) %>%
        select(flight, name, arr_delay) %>%
        rename(arr_airport_name = name) %>%
        filter(!is.na(arr_airport_name)) %>%
        group_by(arr_airport_name) %>%
        summarize(mean_arr_delay = mean(arr_delay, na.rm = TRUE),
                  median_arr_delay = median(arr_delay, na.rm = TRUE),
                  flight_count = n()) %>%
        ungroup() %>%
        filter(flight_count >= 10) %>%
        select(-flight_count) %>%
        arrange(desc(mean_arr_delay))
print(arr_airport_tab, n = Inf)

```

### b

The fastest model is 777-222 and there are 4 flights that model takes.

```{r}
#| code-fold: show
#| code-summary: "The code for Problem 1-b"
#| warning: true
#| error: true

fastest_model <- flights %>%
  select(flight, tailnum, air_time, distance) %>%
  left_join(planes, by = join_by(tailnum == tailnum)) %>%
  select(flight, tailnum, model, air_time, distance) %>%
  filter(!is.na(model) & !is.na(air_time) & !is.na(distance)) %>%
  group_by(model) %>%
  summarize(average_speed = mean(distance / (air_time / 60)),
            num_of_flight = n()) %>%
  ungroup() %>%
  filter(average_speed == max(average_speed))
print(fastest_model)
```

## Problem 2 - `get_temp()`

In the following code, we define the `get_temp()` and load the data.

```{r}
#| echo: false

options(dplyr.summarise.inform = FALSE)

```

```{r}
#| code-fold: show
#| code-summary: "The code for Problem 2"
#| warning: true
#| error: true

# load the NNMAPS data
nnmaps <- readr::read_delim("./data/chicago-nmmaps.csv", show_col_types = FALSE)


#' This function will output the average temperature for a given month.
#'
#' @param month the user input month, either a numeric 1-12 or a string.
#' @param year the user input numeric year.
#' @param data the data set to obtain data from.
#' @param celsius indicates whether the results should be in celsius. (default: `FALSE`)
#' @param average_fn a function which to compute the mean. (default: `mean`)
#'
#' @return a numeric vector of length 1 indicating the average temperature for a given month
get_temp <- function(month, year, data,
                     celsius = FALSE, 
                     average_fn = mean) {
  # The month should be a vector of length 1.
  if (length(month) != 1) {
    stop("The input `month` should be a vector of length 1.")
  }
  
  # The year should be a vector of length 1.
  if (length(year) != 1) {
    stop("The input `year` should be a vector of length 1.")
  }
  
  # The year should be a postive integer.
  if (!is.numeric(year) || 
      !(all.equal(year, round(year)) == TRUE) || 
      year <= 0) {
    stop("The input `year` should be a positive integer.")
  }
  
  # Check whether month is a number in range [1, 12] or a valid string.
  month_num <- 0
  if (is.numeric(month)) {
    if (!(all.equal(month, round(month)) == TRUE)) {
      stop("The input `month` should be an integer or str.")
    }
    if (!(month >= 1 && month <= 12)) {
      stop("The input `month` should be in range [1, 12].")
    }
    month_num <- month
  } else if (is.character(month)) {
    if (month == "January" || month == "Jan") {
      month_num <- 1
    } else if (month == "February" || month == "Feb") {
      month_num <- 2
    } else if (month == "March" || month == "Mar") {
      month_num <- 3
    } else if (month == "April" || month == "Apr") {
      month_num <- 4
    } else if (month == "May") {
      month_num <- 5
    } else if (month == "June" || month == "Jun") {
      month_num <- 6
    } else if (month == "July" || month == "Jul") {
      month_num <- 7
    } else if (month == "August" || month == "Aug") {
      month_num <- 8
    } else if (month == "September" || month == "Sep" || month == "Sept") {
      month_num <- 9
    } else if (month == "October" || month == "Oct") {
      month_num <- 10
    } else if (month == "November" || month == "Nov") {
      month_num <- 11
    } else if (month == "December" || month == "Dec") {
      month_num <- 12
    } else {
      stop("The input `month` is a str, but we can't find the corresponding month.")
    }
  } else {
    stop("The input `month` should be an integer or str.")
  }
  
  # The year should appear in the dataset.
  if (!(year %in% unique(data$year))) {
    stop("The input `year` can't be found in the dataset.")
  }
  
  # Rename the year to prevent conflict with the year column in dataset.
  year_input <- year
  
  # Get the average temperature of a given month and year, we also calculate
  # the result in celsius.
  temp_of_month <- data %>%
    select(date, temp, month_numeric, year) %>%
    group_by(year, month_numeric) %>%
    summarize(average_temp = average_fn(temp)) %>%
    ungroup() %>%
    filter(month_numeric == month_num & year == year_input) %>%
    mutate(average_temp_celsius = (average_temp - 32) * (5 / 9))
  
  # Decide whether to give the result in celsius.
  if (celsius) {
    temp_result <- temp_of_month[, "average_temp_celsius", drop = TRUE]
  } else {
    temp_result <- temp_of_month[, "average_temp", drop = TRUE]
  }
  
  return(temp_result)
}

```

We test this function using the following cases.

```{r}
#| code-fold: show
#| code-summary: "The code for Problem 2"
#| warning: true
#| error: true

get_temp("Apr", 1999, data = nnmaps)
get_temp("Apr", 1999, data = nnmaps, celsius = TRUE)
get_temp(10, 1998, data = nnmaps, average_fn = median)
get_temp(13, 1998, data = nnmaps)
get_temp(2, 2005, data = nnmaps)
get_temp("November", 1999, data =nnmaps, celsius = TRUE,
         average_fn = function(x) {
           x %>% sort -> x
           x[2:(length(x) - 1)] %>% mean %>% return
         })

```

## Problem 3 - SAS

### a

In the following code, we import the data from csv file and select the useful variables.

``` sas
/* Set the input and output path. */
%let in_path = ~/my_shared_file_links/jbhender0/input_data;
%let out_path = ~/dyc/output; 
libname in_lib "&in_path."; 
libname out_lib "&out_path.";
  
/* import delimited data with proc import. */
proc import datafile = "&in_path./recs2020_public_v5.csv" out = recs replace;

/* Calculate the number of rooms. Rename the variables we need to use. */
data recs;
    set recs;
    num_of_rooms = BEDROOMS + NCOMBATH + NHAFBATH + OTHROOMS;
    keep DOEID state_postal state_name DOLLAREL PRKGPLC1 num_of_rooms NWEIGHT;
    rename DOEID = id;
    rename DOLLAREL = total_cost;
    rename PRKGPLC1 = has_garage;
    rename NWEIGHT = weight;
run;
```

We calculate effective sample size (ess) and then get the percent of ess for each state.

The results can be found in [Problem 03-a Result](https://github.com/YicunDuanUMich/r_hw04/blob/main/hw04/hw04_03_a_results.html).

As shown in the result, California has the highest percent which is 6.23902%, and Michigan accounts for 2.08956%.

``` sas

/* Sort the data according to state name. */
proc sort
  data = recs
  out = recs; 
  by state_name; 
run; 

/* Calculate the square of weight for each sample. */
data recs;
    set recs;
    weight_sq = weight * weight;
run;

/* Get the sum of weight and sum of weight_sq for each state. */
proc summary data = recs;
  class state_name; 
  output out = recs_ess
    sum(weight) = weight_sum
    sum(weight_sq) = weight_sq_sum;
run; 

/* Calculate the effective sample size (ess). */
data recs_ess; 
  set recs_ess;
  where _type_ = 1; 
  ess = weight_sum * weight_sum / weight_sq_sum; 
  drop _type_;
run;

/* Calculate the sum of ess. */
proc summary data = recs_ess;
    output out = recs_ess_sum (drop = _type_ _freq_)
      sum(ess) = ess_sum;
run;

/* Calculate ess percent. */
data recs_ess;
    set recs_ess;
    if _n_ = 1 then set recs_ess_sum;
    ess_percent = 100 * ess / ess_sum;
run;

/* Prepare the data for output. */
proc sql;
    create table recs_state_ess as
        select state_name, ess, ess_percent
          from recs_ess
        order by -ess_percent;
quit;
run;

/* Find the ess_percent for Michigan. */
proc sql;
    create table recs_state_ess_mi as
        select state_name, ess, ess_percent
          from recs_ess
        where state_name = "Michigan";
quit;
run;

/* Print the outputs. */
proc print data = recs_state_ess;
proc print data = recs_state_ess_mi;
run;
```

### b

In this section, we draw the histogram of the total electricity cost in dollars.

The result can be found in [Problem 03-b Result](https://github.com/YicunDuanUMich/r_hw04/blob/main/hw04/hw04_03_b_results.html).

``` sas
/* Only choose positive total cost and calculate log(total_cost). */
data recs_positive_total_cost;
    set recs;
    where total_cost > 0;
    log_total_cost = log(total_cost);
run;

/* Draw the histogram of total cost. */
ods graphics on;
proc univariate data = recs_positive_total_cost noprint;
   title "Histogram of Total Cost";
   histogram total_cost / odstitle = title;
run;
```

### c

We draw a histogram of the log of the total electricity cost.

The result can be found in [Problem 03-c Result](https://github.com/YicunDuanUMich/r_hw04/blob/main/hw04/hw04_03_c_results.html).

``` sas

/* Draw the histogram of log total cost. */
ods graphics on;
proc univariate data = recs_positive_total_cost noprint;
   title "Histogram of log(Total Cost)";
   histogram log_total_cost / odstitle = title;
run;
```

### d

We fit a linear regression model predicting the log of the total electricity cost based upon the number of rooms in the house and whether or not the house has a garage.

The result can be found in [Problem 03-d Result](https://github.com/YicunDuanUMich/r_hw04/blob/main/hw04/hw04_03_d_results.html).

``` sas

/* The variable has_garage should be 0 or 1. */
data recs_positive_tc_data_clean;
    set recs_positive_total_cost;
    where has_garage = 0 or has_garage = 1;
run;

/* Get the linear regression model: log(total_cost) ~ num_of_rooms + has_garage */
proc reg data = recs_positive_tc_data_clean;
   title "Linear Regression: log(total_cost) ~ num_of_rooms + has_garage";
   weight weight;
   model log_total_cost = num_of_rooms has_garage;
   output out = out r = r p = p;
run;
```

### e

We create a scatterplot of predicted total electricity cost vs actual total electricity cost.

The result can be found in [Problem 03-e Result](https://github.com/YicunDuanUMich/r_hw04/blob/main/hw04/hw04_03_e_results.html).

``` sas

/* Get the exp(fitted_values) */
data out_e;
    set out;
    e_p = exp(p);
run;

/* create a scatterplot of predicted total electricity cost vs actual total electricity cost. */
proc sgplot data = out_e;
   title "Predictions v.s. Actual Cost";
   scatter x = total_cost y = e_p;
   label total_cost = "Actual Cost" e_p = "Predictions";
run;
```

## Problem 4 - Multiple tools

### b

Load SAS data and select useful variables. `CaseID` takes values in range \[1, 11775\]. `weight_pop` is "Post-stratification weight - Main qualified respondents scaled to U.S. population". `B3` is "Compared to 12 months ago, would you say that you (and your family) are better off, the same, or worse off financially?", which takes values 1, 2, 3, 4, 5 for "Much worse off", "Somewhat worse off", "About the same", "Somewhat better off", "Much better off". `ND2` refers to "Five years from now, do you think that the chance that you will experience a natural disaster or severe weather event will be higher, lower or about the same as it is now?". A higher `ND2` score represents a lower bad weather chance. `B7_b` is "In this country - How would you rate economic conditions today". `B7_b = 1` represents poor, and `B7_b = 5` represents excellent. `GH1`, `ppeducat` and `race_5cat` show the information of home, education and race.

``` sas
/* Set input and output path. */
%let in_path = ~/dyc/input;
%let out_path = ~/dyc/output; 
libname in_lib "&in_path."; 
libname out_lib "&out_path.";

/* Load data. */
data shed;
    set in_lib.public2022;
run;

/* Select useful variables. */
proc sql;
    create table sub_shed as
        select CaseID as case_id,
               weight_pop,
               B3 as finance, 
               ND2 as natural_disaster, 
               B7_b as rate_economic_cond, 
               GH1 as own_or_rent, 
               ppeducat as edu, 
               race_5cat as race
        from shed
        where case_id is not NULL and 
              weight_pop is not NULL and
              finance is not NULL and
              natural_disaster is not NULL and
              rate_economic_cond is not NULL and
              own_or_rent is not NULL and
              edu is not NULL and
              race is not NULL;
quit;
run;
```

### c

We output the data in SAS format.

``` sas
/* Output data. */
data out_lib.sub_shed;
    set sub_shed;
run;
```

### d

In Stata, we load the SAS file and check the number of observations and variables. The `_N` and `r(k)` are 11667 and 8 respectively, which are equal to the values in Codebook.

``` stata
.  import sas using "L:\umich\stat506\r_hw04\data\sub_shed.sas7bdat", clear
(8 vars, 11,667 obs)

.  
.  display _N
11667

.  display `r(k)'
8
```

### e

We convert the response variable to binary.

``` stata

.  replace finance = finance >= 3
(11,667 real changes made)
```

### f

Here is the logistic regression model. We treat variables `natural_disaster` and `rate_economic_cond` as continuous variables and the other variables as categorical. This is because it's meaningful to compare the low and high values of `natural_disaster` and `rate_economic_cond`. As shown in the regression result, the p-value for `natural_disaster` is 0.281, which demonstrates that the coefficient of `natural_disaster` is not significant. Therefore, "the respondent's family is better off, the same, or worse off financially compared to 12 month's ago" **can't** be predicted by "thinking that the chance of experiencing a natural disaster or severe weather event will be higher, lower or about the same in 5 years".

``` stata

.  svyset case_id [pw=weight_pop]

Sampling weights: weight_pop
             VCE: linearized
     Single unit: missing
        Strata 1: <one>
 Sampling unit 1: case_id
           FPC 1: <zero>

. 

.  svy: logit finance c.natural_disaster c.rate_economic_cond i.own_or_rent i.edu i.race
(running logit on estimation sample)

Survey: Logistic regression

Number of strata =      1                        Number of obs   =      11,667
Number of PSUs   = 11,667                        Population size = 255,114,223
                                                 Design df       =      11,666
                                                 F(12, 11655)    =       71.12
                                                 Prob > F        =      0.0000

------------------------------------------------------------------------------------
                   |             Linearized
           finance | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------------+----------------------------------------------------------------
  natural_disaster |   .0329337   .0305301     1.08   0.281    -.0269104    .0927779
rate_economic_cond |   .9718657   .0366155    26.54   0.000     .9000931    1.043638
                   |
       own_or_rent |
                2  |  -.0724622   .0561205    -1.29   0.197    -.1824677    .0375433
                3  |   .0263591   .0582874     0.45   0.651     -.087894    .1406121
                4  |   .3485966   .0989573     3.52   0.000     .1546237    .5425696
                   |
               edu |
                2  |   .0816796   .1031841     0.79   0.429    -.1205785    .2839378
                3  |   .1151752   .1003941     1.15   0.251    -.0816139    .3119644
                4  |   .2446491   .0991822     2.47   0.014     .0502353    .4390629
                   |
              race |
                2  |   .7084782   .0806527     8.78   0.000     .5503855    .8665709
                3  |   .1590003   .0708966     2.24   0.025     .0200311    .2979696
                4  |   .4602344   .1254962     3.67   0.000     .2142409    .7062279
                5  |  -.0264425   .1637874    -0.16   0.872    -.3474932    .2946081
                   |
             _cons |  -1.436843   .1464363    -9.81   0.000    -1.723883   -1.149804
------------------------------------------------------------------------------------

. 

```

### g

We export the data as csv file.

``` stata
. export delimited using "L:\umich\stat506\r_hw04\data\stata_output.csv", replace
(file L:\umich\stat506\r_hw04\data\stata_output.csv not found)
file L:\umich\stat506\r_hw04\data\stata_output.csv saved
```

### h

We load the csv file and get the logistic model. We use two methods to calculate pseudo-$R^2$, as recommended by [psrsq_doc](https://www.rdocumentation.org/packages/survey/versions/4.0/topics/psrsq).

```{r}
#| code-fold: show
#| code-summary: "The code for Problem 4 - h"
#| warning: true
#| error: true

# Load survey package.
library(survey)

# Load csv file.
shed <- read.table("./data/stata_output.csv", sep = ",", header = TRUE)

# Let some variables be factors.
shed$own_or_rent <- as.factor(shed$own_or_rent)
shed$edu <- as.factor(shed$edu)
shed$race <- as.factor(shed$race)

design_weights <- svydesign(id = ~ case_id, weight = ~ weight_pop, data = shed)

# Do regression.
logit_model <- svyglm(finance ~ natural_disaster + rate_economic_cond +
                     own_or_rent + edu + race, 
                     family = quasibinomial(), design = design_weights)
summary(logit_model)

psrsq(logit_model, method = c("Cox-Snell"))
psrsq(logit_model, method = c("Nagelkerke"))

```
